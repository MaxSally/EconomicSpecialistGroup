{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q8QA95OvAwW"
      },
      "source": [
        "from __future__ import print_function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np                 # to use numpy arrays\n",
        "import tensorflow as tf            # to specify and run computation graphs|\n",
        "import tensorflow_datasets as tfds # to load training data\n",
        "import keras\n",
        "import pandas as pd\n",
        "from keras import backend\n",
        "from tensorflow.keras import Model, initializers, regularizers, constraints\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Reshape, Bidirectional, Dense, Input, Dropout, LeakyReLU, Concatenate, PReLU, Flatten\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt \n",
        "from math import sqrt\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxD_HoYCvFOl"
      },
      "source": [
        "\n",
        "inputs = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/AllVariables.csv\")\n",
        "\n",
        "keys = []\n",
        "for it in inputs:\n",
        "    keys.append(it)\n",
        "    \n",
        "distribution = [4, 9, 25, 26] #horrible design\n",
        "\n",
        "number_of_tests = len(inputs[keys[0]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0if9F-tkvig0"
      },
      "source": [
        "input_short_term = []\n",
        "input_long_term = []\n",
        "output = []\n",
        "\n",
        "for i in range(number_of_tests):\n",
        "    instance = []\n",
        "    if pd.isna(inputs[keys[0]][i]):\n",
        "        continue\n",
        "    for j in range(distribution[0], distribution[1]):         \n",
        "        instance.append(round(float(inputs[keys[j]][i])/100, 3))\n",
        "\n",
        "    input_short_term.append(instance)\n",
        "    instance = []\n",
        "    for j in range(distribution[1], distribution[2]):\n",
        "        instance.append(round(float(inputs[keys[j]][i])/100,3))\n",
        "    #for j in range(distribution[3], distribution[4]):\n",
        "    #    instance.append(float(inputs[keys[j]][i])/100)\n",
        "    input_long_term.append(instance)\n",
        "\n",
        "    output.append(float(inputs[keys[distribution[3] - 1]][i])/100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP8SGjrIxLqz"
      },
      "source": [
        "training_input_short_term = []\n",
        "training_input_long_term = []\n",
        "training_output = []\n",
        "\n",
        "testing_input_short_term = []\n",
        "testing_input_long_term = []\n",
        "testing_output = []\n",
        "\n",
        "for i in range(8):\n",
        "    for j in range(13):\n",
        "            training_input_short_term.append(input_short_term[j])\n",
        "            training_input_long_term.append(input_long_term[j])\n",
        "            training_output.append(output[j])\n",
        "    del input_short_term[0:13]\n",
        "    del input_long_term[0:13]\n",
        "    del output[0:13]\n",
        "\n",
        "        #training_input_short_term = np.delete(input_short_term, j)\n",
        "    for k in range(1):\n",
        "        testing_input_short_term.append(input_short_term[k])\n",
        "        testing_input_long_term.append(input_long_term[k])\n",
        "        testing_output.append(output[k])\n",
        "    del input_short_term[0]\n",
        "    del input_long_term[0]\n",
        "    del output[0] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_EfhuhWxO-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0055c3-14dd-467c-f195-0c15fee76e56"
      },
      "source": [
        "print(len(training_input_short_term))\n",
        "print(len(training_input_long_term))\n",
        "print(len(training_input_long_term))\n",
        "\n",
        "print(len(testing_input_short_term))\n",
        "print(len(testing_input_long_term))\n",
        "print(len(testing_output))\n",
        "\n",
        "print(training_input_long_term)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104\n",
            "104\n",
            "104\n",
            "8\n",
            "8\n",
            "8\n",
            "[[0.227, 0.667, 0.218, 0.02, 0.9, 0.87, 0.75, 0.85, 0.82, 0.847, 0.83, 0.5, 0.7, 0.76, 0.131, 0.245], [0.237, 0.666, 0.247, 0.019, 0.9, 0.85, 0.75, 0.97, 0.84, 0.859, 0.83, 0.5, 0.7, 0.77, 0.133, 0.247], [0.24, 0.671, 0.276, 0.019, 0.9, 0.84, 0.76, 0.97, 0.83, 0.807, 0.88, 0.6, 0.7, 0.78, 0.134, 0.245], [0.241, 0.672, 0.295, 0.019, 0.9, 0.85, 0.76, 0.97, 0.83, 0.81, 0.87, 0.7, 0.8, 0.8, 0.136, 0.243], [0.22, 0.668, 0.305, 0.019, 0.9, 0.87, 0.77, 0.97, 0.82, 0.808, 0.88, 0.7, 0.8, 0.81, 0.139, 0.186], [0.235, 0.666, 0.317, 0.018, 0.9, 0.87, 0.77, 0.97, 0.82, 0.754, 0.88, 0.75, 0.8, 0.8, 0.142, 0.194], [0.242, 0.664, 0.327, 0.018, 0.9, 0.87, 0.78, 0.96, 0.82, 0.788, 0.88, 0.75, 0.8, 0.81, 0.144, 0.209], [0.249, 0.662, 0.335, 0.018, 0.9, 0.89, 0.79, 0.97, 0.82, 0.773, 0.88, 0.75, 0.8, 0.8, 0.148, 0.209], [0.249, 0.662, 0.343, 0.017, 0.9, 0.87, 0.8, 0.92, 0.82, 0.752, 0.88, 0.75, 0.8, 0.79, 0.152, 0.216], [0.249, 0.658, 0.352, 0.017, 0.9, 0.88, 0.8, 0.89, 0.83, 0.763, 0.88, 0.8, 0.8, 0.8, 0.156, 0.221], [0.238, 0.656, 0.364, 0.017, 0.9, 0.81, 0.8, 0.89, 0.76, 0.779, 0.88, 0.8, 0.8, 0.79, 0.161, 0.196], [0.228, 0.655, 0.368, 0.017, 0.9, 0.81, 0.8, 0.82, 0.73, 0.769, 0.87, 0.8, 0.8, 0.78, 0.165, 0.191], [0.235, 0.656, 0.379, 0.017, 0.88, 0.82, 0.77, 0.82, 0.73, 0.778, 0.88, 0.8, 0.8, 0.79, 0.168, 0.2], [0.221, 0.537, 0.014, 0.006, 0.5, 0.43, 0.58, 0.7, 0.56, 0.781, 0.8, 0.5, 0.5, 0.59, 0.179, 0.087], [0.262, 0.538, 0.044, 0.006, 0.5, 0.43, 0.61, 0.73, 0.59, 0.787, 0.82, 0.5, 0.5, 0.6, 0.182, 0.154], [0.271, 0.534, 0.091, 0.006, 0.5, 0.43, 0.62, 0.7, 0.58, 0.784, 0.82, 0.5, 0.4, 0.59, 0.184, 0.127], [0.245, 0.532, 0.137, 0.007, 0.5, 0.44, 0.66, 0.7, 0.59, 0.785, 0.81, 0.5, 0.5, 0.61, 0.186, 0.101], [0.183, 0.535, 0.175, 0.006, 0.5, 0.46, 0.67, 0.79, 0.61, 0.788, 0.81, 0.5, 0.5, 0.61, 0.189, 0.059], [0.171, 0.534, 0.207, 0.006, 0.6, 0.47, 0.66, 0.77, 0.55, 0.776, 0.83, 0.6, 0.6, 0.63, 0.191, 0.046], [0.151, 0.528, 0.228, 0.007, 0.5, 0.38, 0.66, 0.76, 0.55, 0.806, 0.83, 0.6, 0.6, 0.6, 0.194, 0.031], [0.128, 0.526, 0.249, 0.007, 0.5, 0.35, 0.65, 0.76, 0.37, 0.726, 0.82, 0.6, 0.6, 0.55, 0.197, 0.072], [0.116, 0.524, 0.271, 0.008, 0.4, 0.34, 0.66, 0.77, 0.42, 0.734, 0.82, 0.65, 0.5, 0.55, 0.201, 0.092], [0.119, 0.521, 0.295, 0.008, 0.4, 0.33, 0.66, 0.76, 0.54, 0.763, 0.83, 0.6, 0.5, 0.56, 0.205, 0.092], [0.102, 0.522, 0.323, 0.01, 0.4, 0.4, 0.64, 0.73, 0.52, 0.778, 0.83, 0.6, 0.5, 0.54, 0.208, 0.092], [0.115, 0.522, 0.341, 0.01, 0.4, 0.43, 0.64, 0.74, 0.5, 0.777, 0.83, 0.6, 0.4, 0.53, 0.211, 0.086], [0.125, 0.522, 0.357, 0.011, 0.53, 0.41, 0.61, 0.74, 0.51, 0.782, 0.82, 0.6, 0.4, 0.55, 0.214, 0.089], [0.247, 0.606, 0.182, 0.032, 0.7, 0.7, 0.71, 0.7, 0.83, 0.906, 0.81, 0.5, 0.3, 0.67, 0.196, 0.283], [0.247, 0.605, 0.206, 0.033, 0.7, 0.69, 0.71, 0.87, 0.84, 0.925, 0.8, 0.7, 0.5, 0.73, 0.202, 0.286], [0.245, 0.607, 0.22, 0.033, 0.7, 0.73, 0.71, 0.91, 0.83, 0.909, 0.8, 0.6, 0.5, 0.73, 0.207, 0.291], [0.245, 0.606, 0.234, 0.033, 0.7, 0.76, 0.7, 0.88, 0.85, 0.943, 0.8, 0.6, 0.5, 0.73, 0.212, 0.274], [0.213, 0.604, 0.256, 0.032, 0.7, 0.75, 0.68, 0.86, 0.83, 0.936, 0.82, 0.6, 0.5, 0.73, 0.218, 0.241], [0.213, 0.601, 0.265, 0.031, 0.8, 0.73, 0.67, 0.85, 0.82, 0.888, 0.82, 0.6, 0.5, 0.73, 0.225, 0.251], [0.221, 0.596, 0.278, 0.032, 0.8, 0.77, 0.67, 0.84, 0.81, 0.879, 0.83, 0.6, 0.5, 0.73, 0.232, 0.242], [0.226, 0.593, 0.281, 0.032, 0.8, 0.78, 0.67, 0.82, 0.81, 0.889, 0.82, 0.6, 0.5, 0.72, 0.239, 0.236], [0.232, 0.596, 0.288, 0.033, 0.8, 0.8, 0.69, 0.81, 0.8, 0.906, 0.82, 0.6, 0.5, 0.72, 0.246, 0.24], [0.239, 0.598, 0.295, 0.034, 0.8, 0.78, 0.69, 0.8, 0.8, 0.875, 0.82, 0.7, 0.5, 0.72, 0.254, 0.247], [0.24, 0.6, 0.304, 0.033, 0.8, 0.74, 0.69, 0.84, 0.9, 0.867, 0.83, 0.7, 0.5, 0.73, 0.26, 0.271], [0.234, 0.605, 0.312, 0.032, 0.8, 0.76, 0.69, 0.83, 0.84, 0.812, 0.83, 0.7, 0.6, 0.73, 0.266, 0.274], [0.24, 0.609, 0.318, 0.032, 0.89, 0.86, 0.69, 0.82, 0.78, 0.83, 0.83, 0.7, 0.6, 0.7, 0.271, 0.281], [0.224, 0.611, 0.019, 0.006, 0.5, 0.52, 0.81, 0.7, 0.72, 0.828, 0.76, 0.3, 0.3, 0.62, 0.044, 0.368], [0.227, 0.609, 0.029, 0.006, 0.5, 0.5, 0.81, 0.69, 0.72, 0.826, 0.77, 0.3, 0.3, 0.62, 0.046, 0.388], [0.234, 0.608, 0.039, 0.007, 0.5, 0.51, 0.82, 0.68, 0.72, 0.801, 0.77, 0.4, 0.4, 0.64, 0.047, 0.388], [0.215, 0.602, 0.049, 0.008, 0.5, 0.5, 0.82, 0.69, 0.72, 0.786, 0.76, 0.4, 0.4, 0.64, 0.048, 0.385], [0.178, 0.605, 0.056, 0.01, 0.5, 0.51, 0.83, 0.71, 0.72, 0.799, 0.78, 0.4, 0.4, 0.65, 0.049, 0.334], [0.234, 0.604, 0.074, 0.01, 0.55, 0.51, 0.84, 0.7, 0.71, 0.767, 0.79, 0.3, 0.5, 0.65, 0.049, 0.335], [0.232, 0.616, 0.087, 0.01, 0.5, 0.45, 0.85, 0.7, 0.79, 0.813, 0.79, 0.45, 0.5, 0.66, 0.051, 0.341], [0.258, 0.626, 0.101, 0.011, 0.5, 0.44, 0.85, 0.78, 0.79, 0.816, 0.79, 0.45, 0.5, 0.66, 0.053, 0.309], [0.259, 0.64, 0.1, 0.012, 0.55, 0.43, 0.85, 0.8, 0.72, 0.798, 0.77, 0.45, 0.5, 0.66, 0.055, 0.294], [0.25, 0.643, 0.102, 0.013, 0.55, 0.44, 0.85, 0.86, 0.79, 0.81, 0.76, 0.55, 0.6, 0.7, 0.058, 0.294], [0.254, 0.644, 0.101, 0.013, 0.55, 0.5, 0.84, 0.94, 0.76, 0.808, 0.8, 0.55, 0.6, 0.71, 0.06, 0.284], [0.26, 0.643, 0.089, 0.014, 0.55, 0.52, 0.85, 0.91, 0.72, 0.845, 0.81, 0.6, 0.6, 0.72, 0.062, 0.284], [0.256, 0.642, 0.086, 0.01, 0.85, 0.52, 0.85, 0.91, 0.73, 0.853, 0.81, 0.6, 0.5, 0.74, 0.064, 0.283], [0.183, 0.552, 0.003, 0.009, 0.5, 0.44, 0.7, 0.7, 0.59, 0.786, 0.78, 0.5, 0.5, 0.63, 0.046, 0.157], [0.202, 0.552, 0.007, 0.009, 0.5, 0.46, 0.7, 0.72, 0.59, 0.837, 0.78, 0.5, 0.5, 0.64, 0.047, 0.172], [0.21, 0.553, 0.008, 0.009, 0.5, 0.45, 0.7, 0.7, 0.59, 0.788, 0.74, 0.5, 0.6, 0.64, 0.047, 0.166], [0.231, 0.556, 0.009, 0.009, 0.5, 0.46, 0.7, 0.71, 0.59, 0.772, 0.74, 0.5, 0.6, 0.63, 0.047, 0.174], [0.207, 0.539, 0.009, 0.008, 0.5, 0.51, 0.69, 0.75, 0.57, 0.743, 0.75, 0.5, 0.6, 0.64, 0.048, 0.175], [0.195, 0.525, 0.014, 0.007, 0.5, 0.49, 0.69, 0.73, 0.59, 0.702, 0.76, 0.45, 0.6, 0.63, 0.048, 0.18], [0.197, 0.525, 0.017, 0.007, 0.5, 0.47, 0.7, 0.72, 0.57, 0.719, 0.77, 0.45, 0.6, 0.63, 0.048, 0.175], [0.2, 0.53, 0.021, 0.007, 0.5, 0.45, 0.71, 0.76, 0.57, 0.75, 0.76, 0.45, 0.6, 0.63, 0.048, 0.151], [0.212, 0.537, 0.03, 0.007, 0.5, 0.41, 0.71, 0.75, 0.56, 0.758, 0.76, 0.45, 0.6, 0.62, 0.049, 0.154], [0.205, 0.54, 0.031, 0.008, 0.5, 0.42, 0.69, 0.75, 0.54, 0.753, 0.76, 0.55, 0.6, 0.63, 0.05, 0.157], [0.209, 0.554, 0.025, 0.008, 0.5, 0.42, 0.7, 0.73, 0.62, 0.749, 0.77, 0.5, 0.6, 0.63, 0.05, 0.165], [0.192, 0.555, 0.02, 0.008, 0.5, 0.44, 0.7, 0.7, 0.59, 0.746, 0.77, 0.45, 0.6, 0.62, 0.051, 0.165], [0.188, 0.562, 0.02, 0.008, 0.68, 0.48, 0.7, 0.62, 0.59, 0.758, 0.77, 0.4, 0.5, 0.62, 0.052, 0.161], [0.294, 0.569, 0.114, 0.011, 0.7, 0.69, 0.55, 0.7, 0.49, 0.839, 0.8, 0.7, 0.7, 0.67, 0.167, 0.221], [0.306, 0.576, 0.151, 0.012, 0.7, 0.71, 0.55, 0.79, 0.5, 0.839, 0.82, 0.7, 0.7, 0.68, 0.167, 0.217], [0.304, 0.581, 0.177, 0.012, 0.7, 0.7, 0.55, 0.78, 0.49, 0.785, 0.87, 0.7, 0.8, 0.69, 0.167, 0.21], [0.284, 0.588, 0.198, 0.013, 0.7, 0.68, 0.55, 0.78, 0.5, 0.781, 0.86, 0.7, 0.8, 0.69, 0.168, 0.196], [0.233, 0.591, 0.21, 0.014, 0.7, 0.67, 0.59, 0.77, 0.48, 0.789, 0.86, 0.8, 0.8, 0.7, 0.169, 0.192], [0.223, 0.593, 0.227, 0.014, 0.7, 0.65, 0.58, 0.76, 0.47, 0.777, 0.88, 0.8, 0.8, 0.7, 0.171, 0.186], [0.206, 0.593, 0.237, 0.013, 0.7, 0.61, 0.61, 0.77, 0.53, 0.824, 0.88, 0.8, 0.8, 0.7, 0.173, 0.179], [0.184, 0.593, 0.245, 0.013, 0.7, 0.61, 0.61, 0.81, 0.52, 0.815, 0.87, 0.8, 0.8, 0.69, 0.176, 0.185], [0.172, 0.59, 0.261, 0.013, 0.7, 0.62, 0.54, 0.8, 0.54, 0.799, 0.87, 0.8, 0.7, 0.68, 0.18, 0.193], [0.179, 0.586, 0.278, 0.012, 0.7, 0.63, 0.54, 0.77, 0.52, 0.799, 0.88, 0.8, 0.7, 0.67, 0.183, 0.196], [0.19, 0.585, 0.29, 0.012, 0.7, 0.59, 0.53, 0.78, 0.53, 0.813, 0.88, 0.85, 0.7, 0.68, 0.186, 0.21], [0.188, 0.583, 0.303, 0.012, 0.7, 0.6, 0.58, 0.76, 0.52, 0.847, 0.88, 0.85, 0.7, 0.69, 0.189, 0.219], [0.194, 0.58, 0.314, 0.012, 0.71, 0.57, 0.63, 0.67, 0.55, 0.855, 0.87, 0.85, 0.7, 0.64, 0.191, 0.222], [0.178, 0.618, 0.164, 0.016, 0.9, 0.87, 0.62, 0.85, 0.79, 0.85, 0.8, 0.9, 0.9, 0.79, 0.16, 0.157], [0.182, 0.621, 0.214, 0.016, 0.9, 0.86, 0.62, 0.92, 0.81, 0.867, 0.82, 0.9, 0.9, 0.8, 0.161, 0.151], [0.185, 0.619, 0.254, 0.016, 0.9, 0.86, 0.62, 0.91, 0.79, 0.813, 0.87, 0.9, 0.9, 0.8, 0.162, 0.15], [0.175, 0.622, 0.279, 0.016, 0.9, 0.86, 0.61, 0.91, 0.8, 0.807, 0.86, 0.9, 0.9, 0.79, 0.163, 0.135], [0.149, 0.62, 0.284, 0.017, 0.9, 0.84, 0.61, 0.9, 0.79, 0.804, 0.86, 0.9, 0.9, 0.79, 0.164, 0.117], [0.161, 0.619, 0.302, 0.017, 0.85, 0.77, 0.62, 0.95, 0.73, 0.737, 0.88, 0.9, 0.8, 0.77, 0.166, 0.132], [0.157, 0.618, 0.322, 0.017, 0.85, 0.77, 0.52, 0.95, 0.71, 0.749, 0.88, 0.9, 0.8, 0.75, 0.168, 0.139], [0.158, 0.62, 0.336, 0.016, 0.9, 0.76, 0.56, 0.95, 0.72, 0.739, 0.87, 0.9, 0.8, 0.74, 0.171, 0.124], [0.163, 0.622, 0.355, 0.016, 0.9, 0.78, 0.57, 0.94, 0.72, 0.724, 0.87, 0.9, 0.8, 0.75, 0.174, 0.114], [0.171, 0.623, 0.363, 0.017, 0.9, 0.76, 0.57, 0.92, 0.73, 0.735, 0.88, 0.9, 0.8, 0.75, 0.177, 0.124], [0.174, 0.624, 0.375, 0.017, 0.9, 0.76, 0.63, 0.91, 0.76, 0.744, 0.88, 0.9, 0.8, 0.76, 0.18, 0.126], [0.174, 0.625, 0.384, 0.017, 0.9, 0.78, 0.65, 0.86, 0.72, 0.764, 0.88, 0.9, 0.8, 0.76, 0.182, 0.121], [0.175, 0.625, 0.39, 0.017, 0.94, 0.78, 0.65, 0.9, 0.73, 0.85, 0.87, 0.9, 0.8, 0.76, 0.183, 0.139], [0.234, 0.65, 0.173, 0.025, 0.9, 0.75, 0.69, 0.85, 0.95, 0.857, 0.8, 0.7, 0.9, 0.8, 0.123, 0.183], [0.235, 0.652, 0.202, 0.026, 0.9, 0.75, 0.69, 0.93, 0.98, 0.85, 0.81, 0.7, 0.9, 0.81, 0.124, 0.193], [0.226, 0.65, 0.239, 0.026, 0.9, 0.76, 0.69, 0.91, 0.95, 0.838, 0.87, 0.8, 0.8, 0.81, 0.125, 0.176], [0.211, 0.65, 0.254, 0.028, 0.9, 0.73, 0.68, 0.93, 0.95, 0.837, 0.87, 0.8, 0.8, 0.81, 0.126, 0.154], [0.178, 0.643, 0.261, 0.028, 0.9, 0.72, 0.68, 0.92, 0.95, 0.84, 0.87, 0.8, 0.8, 0.81, 0.128, 0.14], [0.187, 0.636, 0.274, 0.027, 0.85, 0.73, 0.68, 0.91, 0.95, 0.781, 0.87, 0.75, 0.7, 0.78, 0.13, 0.155], [0.191, 0.63, 0.283, 0.028, 0.85, 0.75, 0.68, 0.91, 0.96, 0.774, 0.86, 0.75, 0.7, 0.78, 0.133, 0.166], [0.2, 0.63, 0.295, 0.027, 0.85, 0.71, 0.7, 0.91, 0.96, 0.772, 0.86, 0.7, 0.7, 0.76, 0.136, 0.189], [0.204, 0.625, 0.303, 0.027, 0.85, 0.71, 0.69, 0.91, 0.96, 0.75, 0.86, 0.7, 0.7, 0.76, 0.139, 0.193], [0.208, 0.622, 0.307, 0.027, 0.8, 0.72, 0.66, 0.89, 0.97, 0.754, 0.87, 0.7, 0.7, 0.76, 0.143, 0.205], [0.212, 0.62, 0.319, 0.027, 0.8, 0.73, 0.66, 0.89, 0.99, 0.766, 0.87, 0.7, 0.7, 0.76, 0.146, 0.203], [0.204, 0.622, 0.327, 0.028, 0.8, 0.74, 0.66, 0.85, 0.91, 0.77, 0.87, 0.7, 0.7, 0.75, 0.15, 0.187], [0.206, 0.623, 0.34, 0.028, 0.81, 0.78, 0.65, 0.84, 0.91, 0.801, 0.87, 0.8, 0.7, 0.75, 0.154, 0.186]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_tR8fM-xQc4"
      },
      "source": [
        "Capital_Investment_train = []\n",
        "Labor_Force_Participation_train = []\n",
        "Fixed_Broadband_train = []\n",
        "RandD_train = []\n",
        "Property_Rights_train = []\n",
        "Freedom_From_Corruption_train = []\n",
        "Fiscal_Freedom_train = []\n",
        "Business_Freedom_train = []\n",
        "Labor_Freedom_train = []\n",
        "Monetary_Freedom_train = []\n",
        "Trade_Freedom_train = []\n",
        "Investment_Freedom_train = []\n",
        "Financial_Freedom_train = []\n",
        "Economic_Freedom_Overall_train = []\n",
        "Pop_Above_65_train = []\n",
        "Savings_As_GDP_train = []\n",
        "\n",
        "\n",
        "for i in range(len(training_input_long_term)):\n",
        "    Capital_Investment_train.append(training_input_long_term[i][0])\n",
        "    Labor_Force_Participation_train.append(training_input_long_term[i][1])\n",
        "    Fixed_Broadband_train.append(training_input_long_term[i][2])\n",
        "    RandD_train.append(training_input_long_term[i][3])\n",
        "    Property_Rights_train.append(training_input_long_term[i][4])\n",
        "    Freedom_From_Corruption_train.append(training_input_long_term[i][5])\n",
        "    Fiscal_Freedom_train.append(training_input_long_term[i][6])\n",
        "    Business_Freedom_train.append(training_input_long_term[i][7])\n",
        "    Labor_Freedom_train.append(training_input_long_term[i][8])\n",
        "    Monetary_Freedom_train.append(training_input_long_term[i][9])\n",
        "    Trade_Freedom_train.append(training_input_long_term[i][10])\n",
        "    Investment_Freedom_train.append(training_input_long_term[i][11])\n",
        "    Financial_Freedom_train.append(training_input_long_term[i][12])\n",
        "    Economic_Freedom_Overall_train.append(training_input_long_term[i][13])\n",
        "    Pop_Above_65_train.append(training_input_long_term[i][14])\n",
        "    Savings_As_GDP_train.append(training_input_long_term[i][15])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ISYHI29xSzB"
      },
      "source": [
        "Capital_Investment_test = []\n",
        "Labor_Force_Participation_test  = []\n",
        "Fixed_Broadband_test  = []\n",
        "RandD_test  = []\n",
        "Property_Rights_test  = []\n",
        "Freedom_From_Corruption_test  = []\n",
        "Fiscal_Freedom_test  = []\n",
        "Business_Freedom_test  = []\n",
        "Labor_Freedom_test  = []\n",
        "Monetary_Freedom_test  = []\n",
        "Trade_Freedom_test  = []\n",
        "Investment_Freedom_test  = []\n",
        "Financial_Freedom_test  = []\n",
        "Economic_Freedom_Overall_test  = []\n",
        "Pop_Above_65_test  = []\n",
        "Savings_As_GDP_test  = []\n",
        "\n",
        "    \n",
        "for i in range(len(testing_input_long_term)):\n",
        "    Capital_Investment_test.append(testing_input_long_term[i][0])\n",
        "    Labor_Force_Participation_test.append(testing_input_long_term[i][1])\n",
        "    Fixed_Broadband_test.append(testing_input_long_term[i][2])\n",
        "    RandD_test.append(testing_input_long_term[i][3])\n",
        "    Property_Rights_test.append(testing_input_long_term[i][4])\n",
        "    Freedom_From_Corruption_test.append(testing_input_long_term[i][5])\n",
        "    Fiscal_Freedom_test.append(testing_input_long_term[i][6])\n",
        "    Business_Freedom_test.append(testing_input_long_term[i][7])\n",
        "    Labor_Freedom_test.append(testing_input_long_term[i][8])\n",
        "    Monetary_Freedom_test.append(testing_input_long_term[i][9])\n",
        "    Trade_Freedom_test.append(testing_input_long_term[i][10])\n",
        "    Investment_Freedom_test.append(testing_input_long_term[i][11])\n",
        "    Financial_Freedom_test.append(testing_input_long_term[i][12])\n",
        "    Economic_Freedom_Overall_test.append(testing_input_long_term[i][13])\n",
        "    Pop_Above_65_test.append(testing_input_long_term[i][14])\n",
        "    Savings_As_GDP_test.append(testing_input_long_term[i][15])  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxjSdx1-xUlu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc35909a-fd5a-49d3-9412-534628a699cd"
      },
      "source": [
        "training_input_short_term = np.array(training_input_short_term)\n",
        "training_input_long_term = np.array(training_input_long_term)\n",
        "training_output = np.array(training_output)\n",
        "\n",
        "testing_input_short_term = np.array(testing_input_short_term)\n",
        "testing_input_long_term = np.array(testing_input_long_term)\n",
        "testing_output = np.array(testing_output)\n",
        "\n",
        "Capital_Investment_train = np.array(Capital_Investment_train)\n",
        "Capital_Investment_test = np.array(Capital_Investment_test)\n",
        "\n",
        "Labor_Force_Participation_train = np.array(Labor_Force_Participation_train)\n",
        "Labor_Force_Participation_test  = np.array(Labor_Force_Participation_test)\n",
        "\n",
        "Fixed_Broadband_train = np.array(Fixed_Broadband_train)\n",
        "Fixed_Broadband_test  = np.array(Fixed_Broadband_test)\n",
        "\n",
        "RandD_train = np.array(RandD_train)\n",
        "RandD_test  = np.array(RandD_test)\n",
        "\n",
        "Property_Rights_train = np.array(Property_Rights_train)\n",
        "Property_Rights_test = np.array(Property_Rights_test)\n",
        "\n",
        "Freedom_From_Corruption_train = np.array(Freedom_From_Corruption_train)\n",
        "Freedom_From_Corruption_test  = np.array(Freedom_From_Corruption_test)\n",
        "\n",
        "Fiscal_Freedom_train = np.array(Fiscal_Freedom_train)\n",
        "Fiscal_Freedom_test  = np.array(Fiscal_Freedom_test)\n",
        "\n",
        "Business_Freedom_train = np.array(Business_Freedom_train)\n",
        "Business_Freedom_test  = np.array(Business_Freedom_test)\n",
        "\n",
        "Labor_Freedom_train = np.array(Labor_Freedom_train)\n",
        "Labor_Freedom_test  = np.array(Labor_Freedom_test)\n",
        "\n",
        "Monetary_Freedom_train = np.array(Monetary_Freedom_train)\n",
        "Monetary_Freedom_test  = np.array(Monetary_Freedom_test)\n",
        "\n",
        "Trade_Freedom_train = np.array(Trade_Freedom_train)\n",
        "Trade_Freedom_test  = np.array(Trade_Freedom_test)\n",
        "\n",
        "Investment_Freedom_train = np.array(Investment_Freedom_train)\n",
        "Investment_Freedom_test  = np.array(Investment_Freedom_test)\n",
        "\n",
        "Financial_Freedom_train = np.array(Financial_Freedom_train)\n",
        "Financial_Freedom_test  = np.array(Financial_Freedom_test)\n",
        "\n",
        "Economic_Freedom_Overall_train = np.array(Economic_Freedom_Overall_train)\n",
        "Economic_Freedom_Overall_test  = np.array(Economic_Freedom_Overall_test)\n",
        "\n",
        "Pop_Above_65_train = np.array(Pop_Above_65_train)\n",
        "Pop_Above_65_test  = np.array(Pop_Above_65_test)\n",
        "\n",
        "Savings_As_GDP_train = np.array(Savings_As_GDP_train)\n",
        "Savings_As_GDP_test  = np.array(Savings_As_GDP_test)\n",
        "\n",
        "\n",
        "LVLabel = [\"Capital_Investment_test\", \"Labor_Force_Participation_test\", \"Fixed_Broadband_test\",\n",
        "          \"RandD_test\", \"Property_Rights_test\", \"Freedom_From_Corruption_test\", \"Fiscal_Freedom_test\", \"Business_Freedom_test\",\n",
        "          \"Labor_Freedom_test\", \"Monetary_Freedom_test\", \"Trade_Freedom_test\", \"Investment_Freedom_test\", \"Financial_Freedom_test\",\n",
        "          \"Economic_Freedom_Overall_test\", \"Pop_Above_65_test\", \"Savings_As_GDP_test\"]\n",
        "\n",
        "trainLV = [Capital_Investment_train, Labor_Force_Participation_train, Fixed_Broadband_train,\n",
        "          RandD_train, Property_Rights_train, Freedom_From_Corruption_train, Fiscal_Freedom_train, Business_Freedom_train,\n",
        "          Labor_Freedom_train, Monetary_Freedom_train, Trade_Freedom_train, Investment_Freedom_train, Financial_Freedom_train,\n",
        "          Economic_Freedom_Overall_train, Pop_Above_65_train, Savings_As_GDP_train]\n",
        "\n",
        "testLV = [Capital_Investment_test, Labor_Force_Participation_test, Fixed_Broadband_test,\n",
        "          RandD_test, Property_Rights_test, Freedom_From_Corruption_test, Fiscal_Freedom_test, Business_Freedom_test,\n",
        "          Labor_Freedom_test, Monetary_Freedom_test, Trade_Freedom_test, Investment_Freedom_test, Financial_Freedom_test,\n",
        "          Economic_Freedom_Overall_test, Pop_Above_65_test, Savings_As_GDP_test]\n",
        "\n",
        "print(len(LVLabel))\n",
        "print(len(trainLV))\n",
        "\n",
        "for item in testLV:\n",
        "  print(len(item))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "16\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LogWXh1hx0yf",
        "outputId": "694b1d45-2bb3-408c-e329-7eafcfb88d24"
      },
      "source": [
        "short_term_input1 = Input(shape=(5,))\n",
        "short_term_input2 = Input(shape=(5,))\n",
        "long_term_input1 = Input(shape=(1,))\n",
        "\n",
        "x1 = Dense(50)(short_term_input1)\n",
        "x1 = LeakyReLU(0.2)(x1)\n",
        "x1 = Dropout(0.35)(x1)\n",
        "\n",
        "x1 = Dense(50)(x1)\n",
        "x1 = LeakyReLU(0.2)(x1)\n",
        "x1 = Dropout(0.5)(x1)\n",
        "\n",
        "x1 = Dense(50)(x1)\n",
        "x1 = LeakyReLU(0.2)(x1)\n",
        "\n",
        "con1 = Concatenate(axis=1)([x1, short_term_input2, long_term_input1])\n",
        "con1 = Dropout(0.35)(con1)\n",
        "\n",
        "con1 = Dense(56, activation = \"relu\")(con1)\n",
        "con1 = Dropout(0.2)(con1)\n",
        "\n",
        "con1 = Reshape(target_shape = (1, 56))(con1)\n",
        "\n",
        "con1 = LSTM(100, return_sequences = True)(con1)\n",
        "con1 = Dropout(0.2)(con1)\n",
        "\n",
        "con1 = LSTM(100, return_sequences = True)(con1)\n",
        "con1 = Dropout(0.35)(con1)\n",
        "\n",
        "con1 = LSTM(200, return_sequences = True)(con1)\n",
        "con1 = Dropout(0.35)(con1)\n",
        "con1 = LSTM(100, return_sequences = True)(con1)\n",
        "con1 = LSTM(1, return_sequences = True)(con1)\n",
        "\n",
        "x2 = Dense(1, activation = None)(long_term_input1)\n",
        "x2 = Reshape(target_shape= (1, 1))(x2)\n",
        "x2 = LSTM(100, return_sequences = True)(x2)\n",
        "x2 = LSTM(1, return_sequences = True)(x2)\n",
        "\n",
        "con2 = Concatenate(axis=1)([con1, x2]) \n",
        "\n",
        "output = Dense(1, activation = None)(con2)\n",
        "\n",
        "SingleLongTermmodel = Model(inputs=[short_term_input1, short_term_input2, long_term_input1], outputs=output)\n",
        "SingleLongTermmodel.summary()\n",
        "SingleLongTermmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss='mae', metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "count = 0\n",
        "top = [\"Long term variable\", \"MAE\"]\n",
        "output_list = []\n",
        "for item in trainLV:\n",
        "  print(LVLabel[count])\n",
        "  history = SingleLongTermmodel.fit([training_input_short_term, training_input_short_term, item], training_output, epochs = 40, batch_size = 3, verbose=0)\n",
        "  history2 = SingleLongTermmodel.evaluate(x=[testing_input_short_term, testing_input_short_term, testLV[count]], y=testing_output, batch_size=3, verbose=1)\n",
        "  output_list.append([LVLabel[count], round(history2[0], 4)*100])\n",
        "  count+=1\n",
        "\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/FinalResults.csv', 'w', newline='') as results_file:\n",
        "    writer = csv.writer(results_file)\n",
        "    writer.writerow(top)\n",
        "    writer.writerows(output_list)\n",
        "    count+=1\n",
        "\n",
        "# For easy access\n",
        "# training_input_short_term\n",
        "# training_input_long_term"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_61\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_151 (InputLayer)          [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_304 (Dense)               (None, 50)           300         input_151[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_168 (LeakyReLU)     (None, 50)           0           dense_304[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_300 (Dropout)           (None, 50)           0           leaky_re_lu_168[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_305 (Dense)               (None, 50)           2550        dropout_300[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_169 (LeakyReLU)     (None, 50)           0           dense_305[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_301 (Dropout)           (None, 50)           0           leaky_re_lu_169[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_306 (Dense)               (None, 50)           2550        dropout_301[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_170 (LeakyReLU)     (None, 50)           0           dense_306[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_152 (InputLayer)          [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_153 (InputLayer)          [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_92 (Concatenate)    (None, 56)           0           leaky_re_lu_170[0][0]            \n",
            "                                                                 input_152[0][0]                  \n",
            "                                                                 input_153[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_302 (Dropout)           (None, 56)           0           concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_307 (Dense)               (None, 56)           3192        dropout_302[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_303 (Dropout)           (None, 56)           0           dense_307[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_96 (Reshape)            (None, 1, 56)        0           dropout_303[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_271 (LSTM)                 (None, 1, 100)       62800       reshape_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_304 (Dropout)           (None, 1, 100)       0           lstm_271[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_272 (LSTM)                 (None, 1, 100)       80400       dropout_304[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_305 (Dropout)           (None, 1, 100)       0           lstm_272[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_273 (LSTM)                 (None, 1, 200)       240800      dropout_305[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_308 (Dense)               (None, 1)            2           input_153[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_306 (Dropout)           (None, 1, 200)       0           lstm_273[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_97 (Reshape)            (None, 1, 1)         0           dense_308[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_274 (LSTM)                 (None, 1, 100)       120400      dropout_306[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_276 (LSTM)                 (None, 1, 100)       40800       reshape_97[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_275 (LSTM)                 (None, 1, 1)         408         lstm_274[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_277 (LSTM)                 (None, 1, 1)         408         lstm_276[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_93 (Concatenate)    (None, 2, 1)         0           lstm_275[0][0]                   \n",
            "                                                                 lstm_277[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_309 (Dense)               (None, 2, 1)         2           concatenate_93[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 554,612\n",
            "Trainable params: 554,612\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Capital_Investment_test\n",
            "3/3 [==============================] - 3s 7ms/step - loss: 0.0111 - root_mean_squared_error: 0.0137\n",
            "Labor_Force_Participation_test\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.0166\n",
            "Fixed_Broadband_test\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0153 - root_mean_squared_error: 0.0174\n",
            "RandD_test\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.0114 - root_mean_squared_error: 0.0138\n",
            "Property_Rights_test\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0115 - root_mean_squared_error: 0.0154\n",
            "Freedom_From_Corruption_test\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0116 - root_mean_squared_error: 0.0139\n",
            "Fiscal_Freedom_test\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0111 - root_mean_squared_error: 0.0136\n",
            "Business_Freedom_test\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0111 - root_mean_squared_error: 0.0141\n",
            "Labor_Freedom_test\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0111 - root_mean_squared_error: 0.0137\n",
            "Monetary_Freedom_test\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0132 - root_mean_squared_error: 0.0154\n",
            "Trade_Freedom_test\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0128 - root_mean_squared_error: 0.0151\n",
            "Investment_Freedom_test\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0135 - root_mean_squared_error: 0.0156\n",
            "Financial_Freedom_test\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0116 - root_mean_squared_error: 0.0139\n",
            "Economic_Freedom_Overall_test\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0117 - root_mean_squared_error: 0.0140\n",
            "Pop_Above_65_test\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0111 - root_mean_squared_error: 0.0138\n",
            "Savings_As_GDP_test\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0117 - root_mean_squared_error: 0.0140\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}